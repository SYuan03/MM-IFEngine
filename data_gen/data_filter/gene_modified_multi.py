from ICNet import ICNet
import argparse
import os
import torch
import cv2
from torchvision import transforms
from PIL import Image
import torch.nn.functional as F
import numpy as np
from matplotlib import pyplot as plt
from tqdm import tqdm
import json
import io
import torch.distributed as dist
import math

client = None

parser = argparse.ArgumentParser()
parser.add_argument('-i', '--input', type = str, default = './example')
parser.add_argument('-o', '--output', type = str, default = './out')
parser.add_argument('-d', '--device', type = int, default=0)
parser.add_argument('-c', '--ceph', type = bool, default=False)


def get_rank_and_world_size():
    rank = int(os.environ.get('LOCAL_RANK', 0))  # LOCAL_RANK represents the GPU rank of the current process
    world_size = int(os.environ.get('WORLD_SIZE', 1))  # WORLD_SIZE represents the total number of GPUs
    return rank, world_size

def setup_distributed(rank, world_size):
    torch.cuda.set_device(rank)
    dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)

def cleanup_distributed():
    dist.destroy_process_group()

def merge_json_files(world_size, input_dir, output_file="final_output.jsonl"):
    # the main process collects all the CSV files generated by the subprocesses and merges them
    df_list = []
    for rank in range(world_size):
        temp_file = os.path.join(input_dir, f"scores_{rank}.jsonl")
        if os.path.exists(temp_file):
            df = [json.loads(da) for da in open(temp_file)]
            print(f"Loaded {len(df)} entries from {temp_file}")
            df_list.extend(df)

    # merge all data
    if df_list:
        with open(os.path.join(input_dir, output_file), 'w') as f:
            for data in df_list:
                f.write(json.dumps(data) + '\n')
        print(f"Saved merged CSV: {os.path.join(input_dir, output_file)}")

def blend(ori_img, ic_img, alpha = 0.8, cm = plt.get_cmap("magma")):
    cm_ic_map = cm(ic_img)
    heatmap = Image.fromarray((cm_ic_map[:, :, -2::-1]*255).astype(np.uint8))
    ori_img = Image.fromarray(ori_img)
    blend = Image.blend(ori_img,heatmap,alpha=alpha)
    blend = np.array(blend)
    return blend


def infer_one_image(img_path, ceph=False):
    with torch.no_grad():
        if not ceph:
            ori_img = Image.open(img_path).convert("RGB")
        else:
            img_bytes = client.get(img_path)
            ori_img = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        ori_height = ori_img.height
        ori_width = ori_img.width
        img = inference_transform(ori_img)
        img = img.to(device)
        img = img.unsqueeze(0)
        ic_score, ic_map = model(img)
        ic_score = ic_score.item()
        ic_map = F.interpolate(ic_map, (ori_height, ori_width), mode = 'bilinear')

        ## gene ic map
        ic_map_np = ic_map.squeeze().detach().cpu().numpy()
        out_ic_map_name = os.path.basename(img_path).split('.')[0] + '_' + str(ic_score)[:7] + '.npy'
        out_ic_map_path = os.path.join(args.output, "ic_map", out_ic_map_name)
        os.makedirs(os.path.dirname(out_ic_map_path), exist_ok=True)
        np.save(out_ic_map_path, ic_map_np)

        ## gene blend map
        ic_map_img = (ic_map * 255).round().squeeze().detach().cpu().numpy().astype('uint8')
        blend_img = blend(np.array(ori_img), ic_map_img)
        out_blend_img_name = os.path.basename(img_path).split('.')[0]  + '.png'
        out_blend_img_path = os.path.join(args.output, "blend_img", out_blend_img_name)
        os.makedirs(os.path.dirname(out_blend_img_path), exist_ok=True)
        cv2.imwrite(out_blend_img_path, blend_img)
        return ic_score


def infer_directory(img_dir, ceph=False, world_size=1, rank=0):
    global data

    output = args.output
    os.makedirs(output, exist_ok=True)  # ensure the output directory exists
    if not ceph:
        imgs = os.listdir(img_dir)
        # only keep image files
        imgs = [f for f in imgs if f.endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'webp'))]
    else:
        img_dir = "s3://public-dataset/"
        iterr = client.list("s3://public-dataset/Conceptual_Captions/images-jpg", no_paginate=True)
        imgs = [f for f in iterr if f.endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'webp'))]

    n_samples = len(imgs)
    per_rank_samples = math.ceil(n_samples / world_size)
    start = per_rank_samples * rank
    end = min(n_samples, per_rank_samples * (rank + 1))

    # new output/overall directory
    overall_dir = os.path.join(output, 'overall')
    os.makedirs(overall_dir, exist_ok=True)  # ensure the overall directory exists

    jsonl_file = os.path.join(overall_dir, f"scores_{rank}.jsonl")

    with open(jsonl_file, 'w') as f:
        for i in tqdm(range(start, end)):
            img = imgs[i]
            img_path = os.path.join(img_dir, img)

            score = infer_one_image(img_path, ceph)
            data_entry = {img: score}

            f.write(json.dumps(data_entry) + '\n')

    if world_size > 1:
        dist.barrier()
            
    if rank == 0:
        merge_json_files(world_size, overall_dir, 'final_output.jsonl')

    cleanup_distributed()



if __name__ == "__main__":
    args  = parser.parse_args()

    rank, world_size = get_rank_and_world_size()
    setup_distributed(rank, world_size)
    device = torch.device(f'cuda:{rank}' if torch.cuda.is_available() else 'cpu')

    model = ICNet()
    model.load_state_dict(torch.load('./checkpoint/ck.pth', map_location=torch.device('cpu')))
    model.eval()
    model.to(device)

    inference_transform = transforms.Compose([
        transforms.Resize((512,512)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    if args.ceph:
        infer_directory(args.input, True, world_size, rank)
    else:
        if os.path.isfile(args.input):
            infer_one_image(args.input)
        else:
            infer_directory(args.input, False, world_size, rank)